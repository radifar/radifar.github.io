[{"content":"In the previous post I wrote about why protonation state determination is important and the various method that can be used to determine protonation state. In this post I would like to do a simple case study on how to use empirical-based pK or protonation state prediction using PROPKA and how to use this tool to help preparing the input structure and topology for GROMACS.\nAs a disclaimer, this post does not contain the whole step on how to use pK prediction tool result to guide the preparation of protein structure prior to MD simulation, rather this is only a guide that could be used as pointer and give insight on how straightforward it is to integrate pK prediction tool like PROPKA in preparing \u0026ldquo;correctly\u0026rdquo; protonated protein structure for MD simulation.\nWhy PROPKA? Nowadays PROPKA is widely used for preparing initial protein structure for MD simulation. Many people not realize it but CHARMM GUI is using PROPKA for protonation state determination. Therefore we could use it to compare the result with MD simulation that run on CHARMM. Due to its nature as empirical pK prediction tool, it is fast and have pretty good accuracy when compared with experimental data as shown in a study by Olsson et al (2010).\nPROPKA is also free to use and well documented. The output from PROPKA is human readable and at the same time can be easily parsed with simple Python script. This is very important as explained later in protein protonation automation section below.\nThe input and the end goal We will start from the struture for coagulation factor Xa (PDB ID: 1fjs). Then from here we will retrieve the predicted pK values from PROPKA and use it to prepare the structure in \u0026ldquo;correctly\u0026rdquo; protonated form and its corresponding topology file using gmx2pdb tool. The topology that is used will be derived from CHARMM27 forcefield rtp file that is integrated within GROMACS.\nThings to consider before integrating PROPKA and GROMACS PROPKA and CHARMM have their own subset of acceptable titratable residues. For example as can be seen in the following PROPKA output excerpt, PROPKA only calculate the pK of ASP, GLU, HIS, TYR, LYS, and ARG. In this calculation CYS is never considered as titratable and therefore given the pK value of 99.99. On the other hand CHARMM, as shown by its aminoacids.rtp file in GROMACS data directory, only support the neutral form of ASP, GLU, and LYS but not ARG. And it supports protonated HIS. And only have the topology for neutral CYS and TYR but not the deprotonated form. Therefore we can only multiple protonation state for ASP, GLU, HIS, and LYS only, as these are the only residue that supported by both tool.\nSUMMARY OF THIS PREDICTION Group pKa model-pKa ligand atom-type ASP 24 A 3.10 3.80 ASP 70 A 4.01 3.80 ASP 100 A 3.49 3.80 ASP 102 A 3.40 3.80 ASP 126 A 4.00 3.80 ASP 164 A 2.43 3.80 ASP 185 A 3.30 3.80 ASP 189 A 4.49 3.80 ASP 194 A 3.91 3.80 ASP 205 A 3.52 3.80 ASP 239 A 2.04 3.80 ASP 92 L 3.79 3.80 ASP 95 L 2.73 3.80 ASP 97 L 3.88 3.80 ASP 119 L 3.88 3.80 GLU 21 A 4.05 4.50 GLU 26 A 4.29 4.50 GLU 36 A 3.84 4.50 GLU 37 A 4.89 4.50 GLU 39 A 3.99 4.50 GLU 49 A 4.80 4.50 GLU 74 A 4.20 4.50 GLU 76 A 4.29 4.50 GLU 77 A 6.43 4.50 GLU 80 A 1.62 4.50 GLU 84 A 3.44 4.50 GLU 86 A 4.49 4.50 GLU 97 A 4.66 4.50 GLU 124 A 5.53 4.50 GLU 129 A 3.34 4.50 GLU 146 A 2.83 4.50 GLU 159 A 4.11 4.50 GLU 188 A 3.38 4.50 GLU 217 A 4.04 4.50 GLU 102 L 4.23 4.50 GLU 103 L 4.59 4.50 GLU 138 L 5.07 4.50 HIS 57 A 7.13 6.50 HIS 83 A 6.00 6.50 HIS 91 A 4.69 6.50 HIS 145 A 6.11 6.50 HIS 199 A 3.25 6.50 HIS 101 L 5.94 6.50 CYS 22 A 99.99 9.00 CYS 27 A 99.99 9.00 CYS 42 A 99.99 9.00 CYS 58 A 99.99 9.00 CYS 122 A 99.99 9.00 CYS 168 A 99.99 9.00 CYS 182 A 99.99 9.00 CYS 191 A 99.99 9.00 CYS 220 A 99.99 9.00 CYS 89 L 99.99 9.00 CYS 96 L 99.99 9.00 CYS 100 L 99.99 9.00 CYS 109 L 99.99 9.00 CYS 111 L 99.99 9.00 CYS 124 L 99.99 9.00 CYS 132 L 99.99 9.00 TYR 51 A 10.63 10.00 TYR 60 A 9.00 10.00 TYR 99 A 12.00 10.00 TYR 162 A 12.12 10.00 TYR 185 A 11.08 10.00 TYR 207 A 11.43 10.00 TYR 225 A 12.05 10.00 TYR 228 A 13.92 10.00 TYR 115 L 12.52 10.00 TYR 130 L 10.70 10.00 LYS 23 A 10.39 10.50 LYS 62 A 10.60 10.50 LYS 65 A 11.26 10.50 LYS 90 A 10.65 10.50 LYS 96 A 11.00 10.50 LYS 109 A 10.69 10.50 LYS 134 A 10.28 10.50 LYS 147 A 10.52 10.50 LYS 156 A 9.29 10.50 LYS 169 A 10.11 10.50 LYS 186 A 11.66 10.50 LYS 204 A 10.55 10.50 LYS 223 A 10.39 10.50 LYS 224 A 10.43 10.50 LYS 230 A 9.12 10.50 LYS 236 A 10.85 10.50 LYS 243 A 11.25 10.50 LYS 87 L 10.30 10.50 LYS 122 L 11.41 10.50 LYS 134 L 9.60 10.50 ARG 63 A 12.44 12.50 ARG 67 A 11.86 12.50 ARG 71 A 11.84 12.50 ARG 93 A 12.44 12.50 ARG 107 A 12.78 12.50 ARG 115 A 12.01 12.50 ARG 125 A 13.73 12.50 ARG 143 A 11.94 12.50 ARG 150 A 12.31 12.50 ARG 154 A 12.41 12.50 ARG 165 A 11.48 12.50 ARG 202 A 12.52 12.50 ARG 222 A 13.72 12.50 ARG 240 A 12.18 12.50 ARG 113 L 10.61 12.50 N+ 16 A 6.87 8.00 N+ 87 L 7.89 8.00 The two possible approach to the end goal To my knowledge there are two approach that can be used to create the correctly protonated structure. The first one is more straightforward, which is by taking the pK value of each titratable residue and feed it to the gmx2pdb using the -inter option, for example by following the official GROMACS tutorial and adding the -inter option will ask the protonation state for each titratable residue like so:\n\u0026gt; gmx pdb2gmx -f 1fjs_protein.pdb -o 1fjs_processed.gro -inter -water tip3p -ff charmm27 ... Processing chain 1 \u0026#39;A\u0026#39; (1852 atoms, 234 residues) Which LYSINE type do you want for residue 8 0. Not protonated (charge 0) (LSN) 1. Protonated (charge +1) (LYS) Type a number:1 Which LYSINE type do you want for residue 48 0. Not protonated (charge 0) (LSN) 1. Protonated (charge +1) (LYS) Type a number:1 Which LYSINE type do you want for residue 51 0. Not protonated (charge 0) (LSN) 1. Protonated (charge +1) (LYS) Type a number: As we can see in the interactive mode above gmx2pdb will ask the protonation state for every residue which is quite tedious. However, it is possible to automate this interaction using Python or shell script. And as I mentioned in the disclaimer before, I would not write the proof of concept for this script. So this is merely serve as guidance for those whom willing to automate this task.\nThe second approach is by reinventing the wheel, what I mean by this is by rewriting pdb2gmx tool using Python script so that the script can automatically read and parse the pK value from PROPKA then use it to protonate the PDB accordingly using cheminformatics tool like Openbabel or RDKit. Then writing the corresponding topology file based on the structure and its protonation state. Though this step is more complicated, it is easier to test and understand what happens in the background. As it is more modular it can be used for different forcefield and even different MD tool.\nConclusion It is possible to automate the protonation using the pK calculation results from tools like PROPKA and use it to protonate the structure and prepare its corresponding topology file. The caveat is that there are discrepancies between the acceptable titratable residues for each tools. And for structure and topology preparation tool like pdb2gmx unfortunately the protonation states have to be selected through interactive mode, which add hurdle to the automation effort. And although this post is specifically used PROPKA and GROMACS it is possible to apply this methods to other tools as well.\n","permalink":"https://radifar.github.io/posts/2025-02-18-protein-protonation-tools-and-a-simple-case-study-how-to-use-them-for-md-structure-preparation-with-gromacs/","summary":"\u003cp\u003eIn the previous post I wrote about why protonation state determination is important and the various method that can be used to determine protonation state. In this post I would like to do a simple case study on how to use empirical-based pK or protonation state prediction using PROPKA and how to use this tool to help preparing the input structure and topology for GROMACS.\u003c/p\u003e\n\u003cp\u003eAs a disclaimer, this post does not contain the whole step on how to use pK prediction tool result to guide the preparation of protein structure prior to MD simulation, rather this is only a guide that could be used as pointer and give insight on how straightforward it is to integrate pK prediction tool like PROPKA in preparing \u0026ldquo;correctly\u0026rdquo; protonated protein structure for MD simulation.\u003c/p\u003e","title":"Protein protonation tools and a simple case study how to use them for MD structure preparation with GROMACS"},{"content":"\nThe structure, function, and dynamics of proteins are dictated by the molecular interaction between its residues and the interaction with its environment. Some of the most important interactions are hydrogen bond, electrostatic, and non polar interations. And it is important to note that for some residues these interactions were affected by their protonation states. For example the deprotonation of aspartate, glutamate, and cysteine residue will cause them unable to act as hydrogen donor. Also, the protonation or deprotonation of a residue can cause formal charge change, which could modulate the short range and long range electrostatic interactions. Thus, in order to properly model and simulate a protein it is important to calculate the protonation state of the titratable residues in the protein.\nIn this post I would like to talk about the details regarding the protonation state of several titratable residues and how it could affect the structure, function and dynamics of a protein. Then, I would continue with some of the use case where protonation state determination is important in protein-ligand modeling and protein simulations. Lastly, I would like to discuss some of the methods that can be used in determining the protonation states of titratable residues.\nTitratable residues and its protonation states variant Out of 20 common amino acid residues, seven of them are titratable. Which can be categorized to three classes:\nCarboxylic acid residues: aspartic acid and glutamic acid. These residues contain carboxylic acid which is usually negatively charged under physiological pH and may turn neutral under pH 4-5. Ammonium and Guanidinium residues: lysine and arginine. These residues contain basic moiety that have high pK, therefore it is rare to find lysine in neutral state at physiological pH, and even more rare to find neutral arginine even at high pH like 11 or 12. Usually arginine is always treated as positively charged as its pK usually ranging from 12 to 14. Special case residues: cysteine, tyrosine, histidine. Cysteine and tyrosine are basically weakly acidic residues and usually neutral at physiological pH. Cysteine have lower pK than tyrosine and thus although very rare, in some condition it can be deprotonated around physiological pH. Histidine on the other hand is a weakly basic residue, although most of the time the imidazole moiety is neutral under physiological pH, both of the nitrogen atoms in the imidazole ring could be protonated under the right condition. Things that could affect the protonation state of titratable residues There are many factors that could affect the protonation states of titratable residues, but basically they all come down to the microenvironment surrounding the residues, things like the hydrogen bond network, solvent accessibility AKA residue burriedness, and the electrostatic charge.\nFor example, the existence of a proton donor next to carboxylic acid residues might form hydrogen bond and stabilize the negatively charged form of these residues, and thus lowering their pK. In the same way, when charged residue have access to water then the charged form will be stabilized, on the opposite, when it is burried it will be more stable in its neutral form.\nThe electrostatic charge surrounding the titratable residues will depend on the charge. If the electrostatic charge surrounding the residue is the opposite charge then the charged residue will be stabilized and vice versa.\nVarious Method for determining the protonation state of titratable residues To this date, there are four different computational-based approach to predict or determine the protonation states of titratable residues. I would start from the first-principle approach, then continuing to the empirical approach which includes MD and electrostatic-based method, and lastly the most recent approach, the machine learning method.\nQM-MM method One of the most accurate way to determine the protonation states of titratable residues in protein is using QM/MM. Ideally, quantum mechanics can be used to do this, but since protein is very large, doing QM calculation for the whole system is computationally expensive and thus not practical. To tackle this issue, QM can be combined with molecular mechanics (MM) by applying the QM to the residue of interest (i.e. catalytic site, ion channel pore) and its surrounding, then, the rest of the protein is treated with MM.\nThen, multiple protonation state configuration can be simulated with QM/MM to find the relative stability for each configuration. The more titratable residue tested inside QM environment the more configuration that should be simulated, usually the number of configuration is 2n where n is the number of the titratable residues. For example, if the catalytic site being simulated contain Asp213, Asp335, and Lys370 then there should be 8 different configuration that must be simulated as shown in the following table:\nconfig num Asp213 Asp335 Lys370 1 protonated protonated protonated 2 protonated protonated neutral 3 protonated neutral protonated 4 protonated neutral neutral 5 neutral protonated protonated 6 neutral protonated neutral 7 neutral neutral protonated 8 neutral neutral neutral The most stable protonation state for each residues can be derived from the resulting relative stability measured from QM/MM simulation.\nConstant pH Molecular Dynamics This method is similar to the QM/MM simulation, but rather than using QM this method uses full MM for the simulation. Also, the protonation states are allowed to change over time. This is possible by implementing nonequilibrium MD and integrating Monte Carlo so that the protonotation state switch will be accepted if it pass the Metropolis criterion otherwise it will be rejected.\nElectrostatic-based method This method predict the protonation states of titratable residues by calculating the pK values using electrostatic interactions. These are done by calculating the the microenvironment surrounding the titratable residues that might affects the pK value such as the neighboring residues, solvent, ions.\nAfter the pK value is retrieved the protonation states can be predicted by measuring the differences between the pK and the intended pH. It is common to use 1.0 unit as the ptreshold value, for example if the aspartate residue has the pK 5.7 then the aspartate would be considered neutral at pH 6 because the pH-pK difference is only 0.3, but it would be considered as negatively charged at ph 7 because the pH-pK difference is larger than 1.0. The value 1.0 is chosen because according to Henderson-Hasselbach equation (see below) when the difference between pH and pK is 1.0 then the concentration ratio between the neutral state and the ionized state is 1 to 10. Which is good enough to make sure that most of the titratable residue is ionized.\nTo this date, this is the most common method and give good balance between accuracy and speed. There are many tools that use this method such as Delphi, PROPKA, PypKa, and H++.\nMachine-learning method In this decade there are many novel computational chemistry methods that utilize machine-learning to enhance the accuracy and the efficiency of the calculation. Starting from the use of graph neural network for modeling protein-ligand interaction, ANI-2x for QM calculation, to machine-learning based forcefield. Recently, new work that utilizes deep learning for the pK prediction of titratable residues has been published by Reis et al. This method is implemented as command line tool pKAI which has been shown to be comparable with electrostatic-based method such as PROPKA.\npKAI works by using deep learning to learn the relationship between the pK values of titratable residues and its surrounding, and generate the model that could predict the pK based on the residue name and its surrounding. Like the previous method, the predicted pK can be used to determine the protonation state of the residue.\nConcluding remark Protonation state determination is a crucial step in protein preparation prior to molecular simulation as it may affects how it binds with other molecule, the stability of the protein structure, and how realistic and how close it resembles the protein structure and behavior in nature.\nThere are several things that need to be considered in determining the protonation state of titratable residues. First, do we have to predict accurately the protonation state of few residue of interest, or we need to determine all of the protonation state at acceptable accuracy. If it is the former case, like in the simulation of catalytic site or ion transportation in a protein then it would be best to use very accurate method but focused on small portion of the protein like QM/MM or in some case CpHMD could give reasonable accuracy for this. On the other hand, if it is the latter case, than electrostatic-based method or ML-based method should do. To compare which one is best for your research it is best to learn from their benchmarking.\n","permalink":"https://radifar.github.io/posts/2025-02-14-protonation-state-determination-of-amino-acid-residues-for-molecular-modeling-and-molecular-simulation/","summary":"\u003cp\u003e\u003cimg loading=\"lazy\" src=\"/assets/img/cover_protonation_protein.jpg\"\u003e\u003c/p\u003e\n\u003cp\u003eThe structure, function, and dynamics of proteins are dictated by the molecular interaction between its residues and the interaction with its environment. Some of the most important interactions are hydrogen bond, electrostatic, and non polar interations. And it is important to note that for some residues these interactions were affected by their protonation states. For example the deprotonation of aspartate, glutamate, and cysteine residue will cause them unable to act as hydrogen donor. Also, the protonation or deprotonation of a residue can cause formal charge change, which could modulate the short range and long range electrostatic interactions. Thus, in order to properly model and simulate a protein it is important to calculate the protonation state of the titratable residues in the protein.\u003c/p\u003e","title":"Protonation state determination of amino acid residues in Molecular Modeling and Molecular Simulation"},{"content":"What is a Domain-Specific Language? It is more common than you think. Few of us – computational chemists – have heard the term Domain-Specific Language (DSL for short), even though this is somewhat ubiquitous in our workflow, especially when dealing with molecule visualisation. Don\u0026rsquo;t you believe me? Check out the command you type on VMD, PyMOL, YASARA, or Chimera.\nYASARA command:\nLoadPDB 1crn, download=yes AutoPosOriObj 1, x = 1, y = 10, z = 0, alpha = 0, beta = 0, gamma = 0 ColorRes cys, green ShowRes cys BallStickRes cys AutoRotateObj 1, Y = 1 wait 180 AutoRotateObj 1, Y = 0 ZoomRes Cys 16, step = 50 wait 100 ZoomRes all VMD Tcl/Tk command:\nset crystal [atomselect top \u0026#34;all\u0026#34;] $crystal moveby {10 0 0} $crystal move [transaxis x 40 deg] set sel [atomselect top \u0026#34;hydrophobic and alpha\u0026#34;] $sel get resname $sel get resid $sel get {resname resid} $sel get {x y z} graphics top cylinder {15 0 0} {15 0 10} radius 10 resolution 60 filled no graphics top cylinder {0 0 0} {-15 0 10} radius 5 resolution 60 filled yes graphics top cone {40 0 0} {40 0 10} radius 10 resolution 60 graphics top sphere {65 0 5} radius 10 resolution 80 graphics top triangle {80 0 0} {85 0 10} {90 0 0} graphics top text {40 0 20} \u0026#34;my drawing objects\u0026#34; PyMOL command:\nselect active, (resi 14-20,38) and chain A zoom active hide all show stick, active select active_water, ( (resi 38 and name ND2 and chain A) around 3.5) and (resn HOH) show spheres, active_water alter active_water, vdw=0.5 rebuild isomesh mesh1, 2fofc.map, 1.0, (resi 14-20,38 and chain A), carve=1.6 isomesh mesh1, 2fofc.map, 1.0, active, carve=1.6 color grey, mesh1 bg_color white As you can see, DSL is a programming language that is\u0026hellip; well, as it says, dealing with a specific domain. For example, the DSL used by YASARA, PyMOL, and VMD is for molecular file I/O processing, molecule selection, manipulation, and visualisation. In other words, those DSLs are specifically targeting molecular information, model, and visualisation domain.\nSome other well-known DSLs include R, Matlab, SQL, HTML\u0026amp;CSS, and spreadsheet formulas, which correspond to statistics, modeling, database, webpage, and spreadsheet domain.\nBut then, what are the differences between General Programming Languages (GPLs) like Java, C++, Fortran, or Python compared to DSL? Also, wouldn\u0026rsquo;t it be too much hassle for us to learn a programming language to solve a specific problem? Compared to GPLs, DSL is far simpler because DSL uses far more limited vocabulary, grammar, and syntax. Using vocabulary specific to a particular domain alone is already lowering the learning barrier significantly since the domain expert (e.g., computational chemist) is familiar with the DSL commands (verb or noun). And thus, the domain expert could correlate most of the commands with their mental model. For example, even when a computational chemist never used VMD before, (s)he will immediately understand what protein and within 4.5 of resname TPF means.\nWell, of course, since the commands and operations in DSL are not as rich as GPL, wouldn\u0026rsquo;t that make DSL less expressive than GPL? Ideally, the DSL should be expressive enough to allow the domain expert to solve every problem that (s)he faces in a specific domain. Therefore DSL should be as simple as possible yet still allow the domain expert to express the solution to their problem.\nVoelter, in his book DSL Engineering (2013), explains that one should attempt to make DSL as close as possible to its target domain (Figure 1). Also, ideally, the DSL should not be under-approximated, in which case it lacks the capability to express the solution in its target domain. On the other hand, it should not over-approximate where it is way too complicated (or overengineered) so that it is capable of doing the operation or implementation that is not required, which is somewhat similar to violating the YAGNI principle (Figure 2).\nFigure 1. Program Domain and Program Language are subsets of Program sets. DSL (program language) is supposed to overlap as much as possible with its target domain.\nFigure 2. PL 1 is Program Language 1 (DSL 1) and PL 2 is Program Language 2 (DSL 2), PL 1 is under-approximated while PL 2 is over-approximated.\nOverall, when DSL is carefully designed and implemented, it can be a powerful yet concise tool for domain experts to express the solution in the target domain.\nI believe that is enough explanation for DSL. I choose to explain DSL first so that I can explain to you why we need DSL for molecular interaction analysis in the next section.\nIs it really necessary to bring DSL to molecular interaction analysis? As someone who has been dealing with interaction fingerprinting for more than a decade, I am fully aware of the severe limitation of the solution that can be offered by an Interaction Fingerprinting (IFP) tool.\nFor example, the IFP tools are usually running according to the choices specified in the configuration file. In other cases, it uses a simple form or wizard using GUI or web interface. This way, the path that can be taken is very limited because:\nThe developers expect the users to take only the happy path so that nothing can go wrong. Many things have been taken care of under the hood so that the users do not have to deal with so many technical-level details. Integrating a new solution into the existing software is difficult. For example, in electrostatic interaction analysis, to modify the atom typing algorithm for positively charged atoms, you have to change the code or SMARTS pattern that identifies the positively charged atoms. One way to overcome this is by providing a plugin system that allows the user to integrate a new solution into the IFP tool. FingeRNAt uses this approach to allow user-defined interaction. On the other end of the spectrum, there is ProLIF, a Python library for molecular interaction analysis. This means that rather than using a command line + configuration file or graphical interface, it uses a series of commands that will be executed. The benefit of this approach is the expressiveness of this tool, as it gives the user more control starting from which molecular fragment to analyze, the result from presentation for reporting or further analysis, adding or changing the geometry rule for a particular interaction, and of course defining new scoring function for interaction similarity.\nThe only caveat is, first of all, you should be able to use Python language to a certain degree of mastery. Second, if you are doing an edge case study, there is a chance you have to extend the deeper level implementation in ProLIF which IMO is not trivial.\nAlso, although in theory, it is possible to express every program domain using Python, ProLIF, and RDKit (as one of ProLIF dependencies), in practice trying to implement a program domain that is not implemented by the ProLIF library will not be easy. For example, we can observe in the ProLIF community that few demanded ProLIF be able to present the interaction result at the atomic level. And to overcome this limitation, the ProLIF developer has to change the core source code so that the interactions are not only registered at the residue level but also at the atomic level.\nWhichever the tools that computational chemist use, it seems like there is no end to the creativity and expressiveness in interaction fingerprinting. The feature demands for IFP tools are incredible, starting from support for various file formats, geometric criteria for each interaction, atom typing, molecular interaction variety (nonpolar, electrostatic, pi, etc.), similarity scoring and weighting algorithm, molecule preparation, and presentation of the analysis result. The vastness of the workflow and use case for this methodology could overwhelm the developer of the IFP tool.\nNow that we have seen the good and the bad of each end of the spectrum and a glimpse of the complexity of molecular interaction analysis, I suppose it is time for me to explain how a Domain Specific Language could be a better alternative.\nFirst, let\u0026rsquo;s create an imaginary language to analyse the internal nonpolar interaction inside the protein.\nopen 1znm.pdb select \u0026#34;protein\u0026#34; as prot measure nonpolar in prot present nonpolar at atomic level Looks very neat isn\u0026rsquo;t it? Next, let us specify our atom typing for nonpolar atoms, and then store the result in zinc_finger_nonpolar.txt file.\nopen 1znm.pdb select \u0026#34;protein\u0026#34; as prot specify nonpolar atom with smarts_pattern \u0026#34;[$([CH3X4,CH2X3,CH1X2,F,Cl,Br,I])\u0026amp;!$(**[CH3X4,CH2X3,CH1X2,F,Cl,Br,I])]\u0026#34; measure nonpolar in prot present nonpolar at atomic level into zinc_finger_nonpolar.txt Last, another imaginary language to analyse four different interactions between two molecules:\nopen 6ma7.pdb select \u0026#34;protein\u0026#34; as prot select \u0026#34;resname TPF\u0026#34; as fluconazole measure nonpolar, hbond, electrostatic, pi between prot and fluconazole present all at bitstring level into cyp3a4_bitstring.txt They may seem so simple at first, but what is so incredible and beautiful about this language is how clear and concise yet at the same time, it can incorporate each detail step by step.\nAnd needlessly to say, it is still very simple and may look like a toy. To make it far more powerful we will have to decide the (molecular interaction) domain we are trying to cover. Then we can decide how much control or implementation we could bestow upon our dear user. Something that I will present in the next post.\nRevision Note: Oct 25, 2023: Add link to ProLIF feature request ","permalink":"https://radifar.github.io/posts/lets-create-domain-specific-language-molecular-interaction-analysis/","summary":"\u003ch2 id=\"what-is-a-domain-specific-language-it-is-more-common-than-you-think\"\u003eWhat is a Domain-Specific Language? It is more common than you think.\u003c/h2\u003e\n\u003cp\u003eFew of us – computational chemists – have heard the term Domain-Specific Language (DSL for short), even though this is somewhat ubiquitous in our workflow, especially when dealing with molecule visualisation. Don\u0026rsquo;t you believe me? Check out the command you type on VMD, PyMOL, YASARA, or Chimera.\u003c/p\u003e\n\u003cp\u003eYASARA command:\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode class=\"language-yasara\" data-lang=\"yasara\"\u003eLoadPDB 1crn, download=yes\nAutoPosOriObj 1, x = 1, y = 10, z = 0, alpha = 0, beta = 0, gamma = 0\nColorRes cys, green\nShowRes cys\nBallStickRes cys\nAutoRotateObj 1, Y = 1\nwait 180\nAutoRotateObj 1, Y = 0\nZoomRes Cys 16, step = 50\nwait 100\nZoomRes all\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eVMD Tcl/Tk command:\u003c/p\u003e","title":"Lets Create A Domain-Specific Language for Molecular Interaction Analysis!"},{"content":"Prerequisite Basic command prompt Basic Python (variable type, collection, loop, decision, and functions) Python virtual environment (conda/mamba) Jupyter notebook/lab Create new environment So first as always, start with creating new environment (preferably mamba). If you have never used mamba before and have some experience with conda then great, you can simply change every conda command with mamba and vice versa.\nCreate new environment for this series using this command:\nmamba create -n learn-open-babel python=3.9 openbabel pandas jupyterlab rich Brief explanation for the command above:\ncreate -n learn-open-babel means create new environment with the name learn-open-babel. python=3.9 means we choose Python version 3.9.x for this environment. pandas is the data analysis tool that we will be using throughout the series. jupyterlab kind of like jupyter notebook, but I prefer this one because it is easier to deal with multiple file. rich this one is for aesthetic purpose, this package is awesome and make reading the output easier. Next, activate our environment with:\nmamba activate learn-open-babel Test our setup environment Open Babel test First lets try and run Python by typing python and press enter, something like this should appear:\nPython 3.9.12 | packaged by conda-forge | (main, Mar 24 2022, 23:25:59) [GCC 10.3.0] on linux Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;\u0026gt; Next, we will check if Open Babel library installed correctly, type the following command in your Python prompt:\n\u0026gt;\u0026gt;\u0026gt; import openbabel \u0026gt;\u0026gt;\u0026gt; openbabel.__version__ \u0026#39;3.1.0\u0026#39; Lets test this library a bit more…\n\u0026gt;\u0026gt;\u0026gt; from openbabel import openbabel as ob \u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; converter = ob.OBConversion() \u0026gt;\u0026gt;\u0026gt; converter.SetInFormat(\u0026#34;smi\u0026#34;) True \u0026gt;\u0026gt;\u0026gt; ethanol = ob.OBMol() \u0026gt;\u0026gt;\u0026gt; converter.ReadString(ethanol, \u0026#34;OCC\u0026#34;) True \u0026gt;\u0026gt;\u0026gt; ethanol.NumAtoms() 3 \u0026gt;\u0026gt;\u0026gt; ethanol.AddHydrogens() True \u0026gt;\u0026gt;\u0026gt; ethanol.NumAtoms() 9 This is just a simple test to load the openbabel library and try to read the SMILES string of ethanol. I will explain the details in the later part of the series. If you get the same output (True, True, 3, True, 9) most likely your Open Babel installed correctly.\nNext lets do some quick test on Jupyter lab.\nJupyter lab test Now, still in the learn-open-babel environment, lets create new directory for this series. And then run Jupyterlab inside the new directory.\nmkdir open_babel_python cd open_babel_python jupyter lab Your command prompt should take you to your default browser and open the Jupyter lab for you.\nJupyter Lab landing page Nice. Go to the launcher tab, and click the Python icon below the Notebook header. A new untitled notebook should appear and new file untitled.ipynb should appear in the current directory. If you have some experience with Jupyter Notebook, the experience is similar, it just have a better workflow and looks in my opinion.\nIn the next part of this series we will take a look at the basic workflow of opening the molecule file with Open Babel and Python.\n","permalink":"https://radifar.github.io/posts/learn-open-babel-python-00-setup/","summary":"\u003ch2 id=\"prerequisite\"\u003ePrerequisite\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eBasic command prompt\u003c/li\u003e\n\u003cli\u003eBasic Python (variable type, collection, loop, decision, and functions)\u003c/li\u003e\n\u003cli\u003ePython virtual environment (conda/mamba)\u003c/li\u003e\n\u003cli\u003eJupyter notebook/lab\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"create-new-environment\"\u003eCreate new environment\u003c/h2\u003e\n\u003cp\u003eSo first as always, start with creating new environment (preferably mamba). If you have never used mamba before and have some experience with conda then great, you can simply change every conda command with mamba and vice versa.\u003c/p\u003e\n\u003cp\u003eCreate new environment for this series using this command:\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" class=\"chroma\"\u003e\u003ccode class=\"language-bash\" data-lang=\"bash\"\u003e\u003cspan class=\"line\"\u003e\u003cspan class=\"cl\"\u003emamba create -n learn-open-babel \u003cspan class=\"nv\"\u003epython\u003c/span\u003e\u003cspan class=\"o\"\u003e=\u003c/span\u003e3.9 openbabel pandas jupyterlab rich\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eBrief explanation for the command above:\u003c/p\u003e","title":"Learn Open Babel in Python - 00 Setup"},{"content":"There are many ways to improve structure-based virtual screening, from something as simple as screening the ligand based on the physico-chemical properties (MW, number of H-donor, number of aromatic rings, pKa, etc.), using consensus docking, or even post-analysis using FEP-based method.\nOne of the simplest and yet fruitful approach to enhance the virtual screening workflow is using interaction fingerprinting. It has been known for long time that certain interaction from certain residue holds more significance than others. And this is especially true when it comes to receptor, where some residue holds the key for agonism while some others for antagonism (or reverse agonism). This key idea, in turn can be used to analyze the interaction pattern (hence, interaction fingerprinting) to figure out if the ligand is a potential agonist, antagonist, or just a dud.\nWhen I was starting my research (in 2011) on interaction fingerprinting, I found that the earliest use of interaction fingerprinting is in 2004 by Deng et al. under the term Structural Interaction Fingerprinting (SIFt). I do not know if there is any earlier use than that, but if you do please comment below. Back then it was still difficult to find a software that could do interaction fingerprinting. The only (standalone) software I could find was Fingerprintlib by Marcou and Rognan (2007). It is free to use, and you can read the source code too. Now, unfortunately it uses OpenEye Chem library which isn\u0026rsquo;t free back then. Back then, I wanted to use a free (both gratis and open source) tool for interaction fingerprinting, and I thought to myself maybe I could build one with Python programming language!\nFirst, to see if this idea could work I tried to find the alternative(s) for OpenEye Chem. That\u0026rsquo;s when I found out that it turns out OEChem and Open Babel is actually derive from the same code! What a coincidence! And then I\u0026rsquo;m starting by analyzing the algorithm behind Fingerprintlib which is written in C++, alternating between the Fingerprintlib publication paper and reading the code I begin to understand how it works behind the scene. And luckily, the OEChem API and Open Babel API is very similar.\nThe next step, and I think the most difficult part is when I have to learn the Open Babel library. As this is my first time doing a professional programming task, Open Babel is very complicated! There were not many examples on how to use Open Babel in Python library, most of the examples that I found is only from the documentation and O\u0026rsquo;Boyle blog. Therefore I spent 1 month of my time to learn Open Babel API by printing out the Open Babel module I am most likely used: OBMol, OBConversion, OBResidue, OBAtom, etc. then going through lots of trial and error to understand the objects, methods, input, and output from those modules.\nBy the new year eve of 2012 I\u0026rsquo;ve got most of the thing I need to use Open Babel in my library, then I\u0026rsquo;m having my first meeting in a cafe with my colleague, Enade. I can\u0026rsquo;t remember clearly, but for some reason I was riding my bicycle from my home to the cafe, which is about 9 km away as fast as I could that I arrived at the cafe in just 30 minutes LOL. If I remember correctly, the meeting itself was sudden, maybe because I shared some of my \u0026lsquo;fantastic\u0026rsquo; progress to him about using Open Babel \u0026amp; Python to recognize protein structure. And he would like to immediately collaborate with me to produce our own interaction fingerprinting tool.\nOne thing to note is that I was doing this purely out of passion, I didn\u0026rsquo;t receive any compensation apart from having my name came first in our PyPLIF paper. I wasn\u0026rsquo;t doing this to get money either. I really love to share my code to the open source community as I have already receive a lot from them. I also think that it is wonderful to share your work so that other people in the other side of the earth could use it for their work.\nOne month later, by the end of January 2012. PyPLIF alpha is ready! Oh right, I haven\u0026rsquo;t mentioned two important thing. First, PyPLIF can only read/analyze docking results from PLANTS, and second why named with PyPLIF? Back then we have two freely available molecular docking tools, AutoDock Vina and PLANTS. Back then me and Enade didn\u0026rsquo;t use Vina because we didn\u0026rsquo;t like the fact that we have to rely on GUI for every molecule preparation prior to docking (which is turns out to be not true). Second we would like to replicate the study from de Graaf (2011) on SBVS for fragment-like ligands of HRH1, which is using interaction fingerprinting and PLANTS as the docking tool. Since that study is a great success, surely there is a huge potential in using PLANTS and writing an Interaction Fingerprinting tool for PLANTS docking result.\nWhat about PyPLIF? Well, there is a tradition in Python package development where the name of the package begin with Py (which obviously stand for Python). And since the software can be used to analyze protein-ligand interaction hence the name, PyPLIF (Python-based Protein Ligand Interaction Fingerprinting).\nTo check if PyPLIF working as intended we decided to use the simple interaction fingerprint in figure 2 from de Graaf (2011) study. After some comparison and visual inspection we managed to replicate the interaction fingerprint from that. The next step is comparing interaction fingerprint from the whole SBVS campaign. Thanks to the authors courtesy we managed to obtain the interaction fingerprint and start comparing the whole fingerprint. And\u0026hellip; as expected there is a slight differences, which is makes sense because their interaction fingerprinting tool uses OEChem library and our tool uses Open Babel library which in some occasion would recognize molecule/atom in a different way.\nThe next step is of course to publish our work. We didn\u0026rsquo;t aim high back then, therefore we decided to publish PyPLIF in Bioinformation (IF: around 1 when we about to submit our work). And voila! It was accepted as is! No revision or whatsoever. Well, seems like we aim too low. But whatever, I guess that\u0026rsquo;s all for now. The next thing I would like to share is about PyPLIF weaknesses and lack of features. But that will be on the next part.\nHistory 1.0 article ready, without link, or picture. (2020-09-12)\n","permalink":"https://radifar.github.io/posts/2020-09-12-the-story-behind-pyplif-hippos-part-1/","summary":"\u003cp\u003eThere are many ways to improve structure-based virtual screening, from something as simple as screening the ligand based on the physico-chemical properties (MW, number of H-donor, number of aromatic rings, pKa, etc.), using consensus docking, or even post-analysis using FEP-based method.\u003c/p\u003e\n\u003cp\u003eOne of the simplest and yet fruitful approach to enhance the virtual screening workflow is using interaction fingerprinting. It has been known for long time that certain interaction from certain residue holds more significance than others. And this is especially true when it comes to receptor, where some residue holds the key for agonism while some others for antagonism (or reverse agonism). This key idea, in turn can be used to analyze the interaction pattern (hence, interaction fingerprinting) to figure out if the ligand is a potential agonist, antagonist, or just a dud.\u003c/p\u003e","title":"The Story Behind PyPLIF HIPPOS (Part 1)"},{"content":"So yesterday I spent at least 3 hours to deal with Python package development in Conda environment. So I wrote this post as a self-reminder, since the steps are somewhat long. And also for those of you who is facing the same problem as I do.\nWhy do I need to use pip when I can use Conda to install Open Babel If you\u0026rsquo;re an experienced Python package developer you should have known the following trick:\npip install -e .\nFor those of you who do not know, this command is for installing your package in editable mode, which means every change you made to your package will immediately reflected to your environment without having to reinstall your package. Amazing huh?\nThis trick is very useful when I was developing my package and I was satisfied, until\u0026hellip; I made the change to setup.py in order to stage my package to conda-forge so my package can be installed using conda. And then I just figured it out when there is some minor bug in my package recently, and debugging would be much easier if I could see the result every time I patch the code.\nBut alas, for some reason pip install -e . just doesn\u0026rsquo;t work anymore. Well, the first reason is one of my package dependency (Open Babel) can only be installed with Conda or package manager (apt, yum, etc.), and since I added package dependency to setup.py pip will try to install Open Babel which doesn\u0026rsquo;t work. The second reason was, when I run pip install -e . --no-deps with the assumption that my package will use Open Babel from Conda environment, but that doesn\u0026rsquo;t work because package installed with pip in editable mode can not recognize the conda environment.\nMy first approach is by googling the workaround for pip editable mode in Conda environment, but the answers I found were too complicated and require me to create new Conda environment everytime I want to use the development environment via pip install -e . . And then the other alternative is using conda develop command, which is an alternative for pip install -e .. But too bad that conda develop has been abandoned and can not serve its purpose since what I really need is the entrypoint so that every time I update the code I can check my package by typing hippos or hippos-genref command.\nsetup.py come to rescue And then finally, I use my last resort. That is\u0026hellip; by installing Open Babel to my pip environment (inside my Conda environment) from the source. First of all I follow the build instruction for Open Babel. After making sure the requirement satisfied (especially SWIG for SWIG binding)\ntar -zxf openbabel-openbabel-3-1-1.tar.gz cd openbabel-openbabel-3-1-1 mkdir ob-build cd $_ cmake -DRUN_SWIG=ON -DPYTHON_BINDINGS=ON -DCMAKE_INSTALL_PREFIX=../openbabel-install .. make -j4 install And then using the Open Babel pip source file to install Open Babel Python binding to my pip environment with the following command:\ntar -zxf openbabel-3.1.1.1.tar.gz cd openbabel-3.1.1.1 python setup.py build_ext -I ~/radifar.pro/openbabel/openbabel-openbabel-3-1-1/openbabel-install/include/openbabel3/ -L ~/radifar.pro/openbabel/openbabel-openbabel-3-1-1/openbabel-install/lib/ python setup.py install Note here that the -I and -L option is to specify the Open Babel Include and Library directory where you install your Open Babel.\nThen check if Open Babel is installed in pip environment inside Conda environment using conda env export:\n... - xorg-xproto=7.0.31=h14c3975_1007 - xz=5.2.5=h516909a_1 - zlib=1.2.11=h516909a_1006 - pip: - attrs==19.3.0 - coverage==5.2.1 - importlib-metadata==1.7.0 - more-itertools==8.4.0 - openbabel==3.1.0 - packaging==20.4 - pluggy==0.13.1 - py==1.9.0 - pyparsing==2.4.7 - pytest==5.4.3 - pytest-cov==2.10.0 - six==1.15.0 - wcwidth==0.2.5 - zipp==3.1.0 Then check if Open Babel can be imported from my Conda environment:\nPython 3.7.8 | packaged by conda-forge | (default, Jul 23 2020, 03:54:19) [GCC 7.5.0] on linux Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;\u0026gt; from openbabel import openbabel \u0026gt;\u0026gt;\u0026gt; Great! Now Open Babel is running perfectly under pip in Conda environment. OK, so that\u0026rsquo;s all folks. Hope this post can help solve your problem. And if you have any question feel free to ask in the comment section below.\n","permalink":"https://radifar.github.io/posts/2020-08-26-editable-pip-in-conda-env/","summary":"\u003cp\u003eSo yesterday I spent at least 3 hours to deal with Python package development in Conda environment. So I wrote this post as a self-reminder, since the steps are somewhat long. And also for those of you who is facing the same problem as I do.\u003c/p\u003e\n\u003ch3 id=\"why-do-i-need-to-use-pip-when-i-can-use-conda-to-install-open-babel\"\u003eWhy do I need to use pip when I can use Conda to install Open Babel\u003c/h3\u003e\n\u003cp\u003eIf you\u0026rsquo;re an experienced Python package developer you should have known the following trick:\u003c/p\u003e","title":"Installing Open Babel with Pip"},{"content":"Who Am I My name is Muhammad Radifar, but when you contact me just call me Radif. I am from Indonesia. Currently I am a\nIndependent Researcher @PICompS Freelancer Research Assistant Computational Chemist, experienced with Molecular Dynamics NAMD GROMACS Homology Modeling Modeller Molecular Docking AutoDock Vina PLANTS Molecule Visualization VMD Software Engineer (Python), experienced with Open Babel Jupyter Notebook Sphinx documentation Full Stack Developer Front End: Vue Back End: Django API: GraphQL Would Like To Know Me Better? See My Projects link above. Or click on my Github, Twitter, or Linkedin links below.\n","permalink":"https://radifar.github.io/about/","summary":"\u003ch1 id=\"who-am-i\"\u003eWho Am I\u003c/h1\u003e\n\u003cp\u003eMy name is Muhammad Radifar, but when you contact me just call me Radif.\nI am from Indonesia. Currently I am a\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eIndependent Researcher @\u003ca href=\"https://picomps.org/profile/muhammad-radifar/\"\u003ePICompS\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eFreelancer\u003c/li\u003e\n\u003cli\u003eResearch Assistant\u003c/li\u003e\n\u003cli\u003eComputational Chemist, experienced with\n\u003cul\u003e\n\u003cli\u003eMolecular Dynamics\n\u003cul\u003e\n\u003cli\u003eNAMD\u003c/li\u003e\n\u003cli\u003eGROMACS\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eHomology Modeling\n\u003cul\u003e\n\u003cli\u003eModeller\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eMolecular Docking\n\u003cul\u003e\n\u003cli\u003eAutoDock Vina\u003c/li\u003e\n\u003cli\u003ePLANTS\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eMolecule Visualization\n\u003cul\u003e\n\u003cli\u003eVMD\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eSoftware Engineer (Python), experienced with\n\u003cul\u003e\n\u003cli\u003eOpen Babel\u003c/li\u003e\n\u003cli\u003eJupyter Notebook\u003c/li\u003e\n\u003cli\u003eSphinx documentation\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eFull Stack Developer\n\u003cul\u003e\n\u003cli\u003eFront End: Vue\u003c/li\u003e\n\u003cli\u003eBack End: Django\u003c/li\u003e\n\u003cli\u003eAPI: GraphQL\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"would-like-to-know-me-better\"\u003eWould Like To Know Me Better?\u003c/h1\u003e\n\u003cp\u003eSee \u003cstrong\u003eMy Projects\u003c/strong\u003e link above. Or click on my Github, Twitter, or Linkedin links below.\u003c/p\u003e","title":"About Me"}]